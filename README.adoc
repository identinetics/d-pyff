# Deploy pyFF using docker

A docker image for running a pyFF instance in either of 2 modes:
    1. daemon mode (mdx service and idp discovery as implemented by pyff/mdx).
    2. batch mode (metadata aggregator as implemented by pyff/md).

The image produces immutable containers, i.e. a container can be removed and re-created
any time without loss of data, because data is stored on mounted volumes.

The image is prepared for for metadata signature creation with pkcs#11 devices.

## Prepare project and build the docker image

    git clone --recurse-submodules --shallow-submodules https://github.com/identinetics/docker-pyff
    cd docker-pyff
    cp conf.sh.default conf.sh # adapt afer copying
    ./dscripts/build.sh

   Option: To run multiple pyff containers on the same system you need to create separate conf.sh files
   and build separate images:
   E.g. to create pyff container instance 03:
   a) create a file conf03.sh, and set the IMGID=3; and
   b) build the container with the -n option, e.g. `./dscripts/build.sh -n 03`
   c) run the container with the -n option, e.g. `./dscripts/run.sh -n 03`


## Usage: pyffd
Initialize mounted volumes with sample data (optional):
    
    ./dscripts/run.sh -i init_sample.sh

Configure pyff: 
    Copy a default file to /etc/pyff/md_aggregate_sign.fd and adjust the settings.
    (/etc/pyff is the interal path of the container, see conf.sh for the extermanl mapping)


Start pyffd as discovery and mdx service:
Configure env variables (in conf.sh):
    FREQUENCY
    LOGLEVEL 
    PIDFILE
    PIPELINEDAEMON

    run.sh
    curl http://localhost:8080
    
Take care of appropriate port mapping and/or proxying

Documentation: See http://leifj.github.io/pyFF


## Usage: pyFF/batch mode

### Preconditiona: 
* The container needs to be running already (usually as a pyffd). 
* The `docker run` command needs to contain:
    * 3 enviroment variables: LOGFILE, LOGLEVEL and PIPELINE;
    * The volumes referenced in LOGFILE and PIPELINE must be mounted to the container;
    * pyff shall not be run as root, but the user defined with CONTAINERUSER and CONTAINERUID in
      conf.sh

### Github authentication
If the git pull/push operations require authentication your need to provide a default ssh keypair
and register it with Github (Gitlab, ..) in the home directory of the container user, such as:

    dscripts/exec.sh
    ssh-keygen -t ed25519
    # add ~/.ssh/id_ed25519.pub as a deploy key with write access to the remote repo
    ssh git@github.com  # validate that the github key fingerprint is valid
    git config --global push.default simple
     
### Run aggregator

Start pyff:
 
    # see exec_pyff_batch.sh -h for options with per-entity-descriptor outpout and git integration
    ./exec_pyff_batch.sh

Sample entry for /etc/crontab to run pyff every hour:

    29 *  *  *  *  root /docker_images/pyff/exec_pyff_batch.sh 2>&1 > /var/log/exec_pyff_batch.log
   
    
## HSM/pyFF config

Config the key name in md_aggregate_sign.fd to match the key name on the HSM.
(See the line with 'sign -> key')

Provide the PYKCS11PIN env variable if using the HSM

## CI, Staging and Versioning

There are 2 environments defined in the dscripts tool chain:

|===
|environment | docker image tag| git branch
|production | pr | master
|testing | qa | qa
|===

There is a Jenkinsfile for CI. To use is Jenkins must be able to run docker.

Versions are in $Projectroot/VERSION. To tag a new version run:

    git tag $(cat VERSION)
