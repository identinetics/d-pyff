:toc:
= Deploy pyFF using docker

== Overview
Purpose:

1. A docker image for running a pyFF instance in daemon mode (mdx service and idp discovery as implemented by pyff/mdx).
2. The metadata aggregator used the same image and volumes as pyff/mdx, but creat a separte container.

The image is prepared for for metadata signature creation with pkcs#11 devices.


The pyff project includes a Dockerfile based on Ubuntu. The differences of this image are:

- Based on CentOS 7
- Various default, suche as docker-compose configuration
- Includes Jenkinsfile
- Dependencies to use Gemalto eToken HSM
- Does not start as root; drops capabilities
- Automatic generation of image build numbers for both source repo and dependency changes (-> dcshell submodule)
- Function to push the aggregate (md_feed) to a git repo
- Function to generate HTML pages for IDPs and SPs
- Optional signing with XMLSECTOOL (using a java-based library)


== Build

The included Jenkinsfile can be used to build, test and push the docker image.
To build without Jenkins use:

    git clone https://github.com/identinetics/d-pyff
    cd d-pyff
    git submodules update --init
    ./dcshell/build

== Usage

=== General

The configuration controlled in the docker-compose configuration file.
The default file is dc.yaml.default.
The key elements for the behavior of pyff and pyffd are:

* Environment variables
* Configuration in /etc/pki/sign, /etc/pyff
* Input data n /var/md_source

For initial testing copy sample data from /opt/testdata:

    cp -p /opt/testdata/etc/pyff/* /etc/pyff/
    cp -pr /opt/testdata/etc/pki/sign/* /etc/pki/sign/
    cp -pr /opt/testdata/md_source/* /var/md_source/

Other elements in the docker-compose configuration to be adpapted are:

* service and volume names if running mor than one instance on a node
* image (control deployed version with the tag value)
* networks

=== Aggregator running in batch mode (pyff)

Functional enhancements to pyFF:
- Commit generated aggregate to git repo
- Generate HTML pages for IDPs and SPs.
- Generate one signed file per entity 

=== Configuration

. Environment variables
|===
|
| MDSIGN_CERT, MDSIGN_KEY | Key pair for metadata signing, must match pipeline definition (see md/mdx_swcert.fd)
| MD_AGGREGATE | Output file defined in pipeline definition to be use as input for split operation (options -s
| MDFEED_HOST |
| MDFEED_SSHUSER | 
| MDFEED_REPO | 
| MDSPLIT_UNSIGNED | 
| MDSPLIT_SIGNED | 
| PIDFILE | 
| PIPELINEBATCH | 
|===

.Pileline configuration
The pipeline configuration (/etc/pyff/*.fd) controls the selection of the input, processing, signing and output location.
The "finalize" key needs to be adapted accoring to the federation policy.
There might be multiple files, e.g. to separate files for IDPs, SPs and a combined aggregate.

=== Git Authentication
If the git pull/push operations require authentication your need to provide a default ssh keypair
and register it with Github (Gitlab, ..) in the home directory of the container user, such as:

    docker-compose -f dc.yaml exec pyff bash
    ssh-keygen -t ed25519
    # add ~/.ssh/id_ed25519.pub as a deploy key with write access to the remote repo
    ssh -T git@github.com  # validate that the github key fingerprint is valid
    git config --global push.default simple
     
=== Run aggregator

Start pyff:
 
    # see exec_pyff_batch.sh -h for options with per-entity-descriptor outpout and git integration
    ./exec_pyff_batch.sh

Sample entry for /etc/crontab to run pyff every hour:

    29 *  *  *  *  root /docker_images/pyff/exec_pyff_batch.sh 2>&1 > /var/log/exec_pyff_batch.log
   
    
== HSM/pyFF config

Config the key name in md_aggregate_sign.fd to match the key name on the HSM.
(See the line with 'sign -> key')

Provide the PYKCS11PIN env variable if using the HSM.


=== IDP discovery and MDQ service (pyffd)

pyffd needs a pipeline definition (e.g. /opt/testdata/etc/pyff/mdx_softhsm.fd) and
key material either as sw-certificate or PKCS11 device.
The file with the pipeline definition must match PIPELINEDAEMON in dc.yaml.
Modify the configuration to reflect your metadata policy.


Configure environment variables in dc.yaml and start the daemon:


. Environment variables
|===
| MDSIGN_CERT |
| MDSIGN_KEY |
| FREQUENCY |
| PIPELINEDAEMON |
|===


    docker-compose -f dc.yaml up -d
    curl http://localhost:8080

Take care of appropriate port mapping and/or proxying.

Documentation: See https://github.com/IdentityPython/pyFF



== CI, Staging and Versioning

There is a Jenkinsfile for CI. To use it the jenkins user:

 * Must be able to run docker and docker-compose;
 * Must have python3 in the path;
 * Must have pytest and pyYaml installed in python3

== checking for errors

By default, pyff is rather silent and does not output error conditions (to be fixed).
For tracking problems:

    export LOGLEVEL=DEBUG
