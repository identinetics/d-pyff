:toc:
= Deploy pyFF using docker

== Overview
Purpose:

1. A docker image for running a pyFF instance in daemon mode (mdx service and idp discovery as implemented by pyff/mdx).
2. The metadata aggregator used the same image and volumes as pyff/mdx, but creat a separte container.

The image is prepared for for metadata signature creation with pkcs#11 devices.


The pyff project includes a Dockerfile based on Ubuntu. The differences of this image are:

- Based on CentOS 7
- Various default, suche as docker-compose configuration
- Includes Jenkinsfile
- Dependencies to use Gemalto eToken HSM
- Does not start as root; drops capabilities
- Automatic generation of image build numbers for both source repo and dependency changes (-> dcshell submodule)
- Function to push the aggregate (md_feed) to a git repo
- Function to generate HTML pages for IDPs and SPs
- Optional signing with XMLSECTOOL (using a java-based library)


== Build

The included Jenkinsfile can be used to build, test and push the docker image.
To build without Jenkins use:

    git clone https://github.com/identinetics/d-pyff
    cd d-pyff
    git submodules update --init
    ./dcshell/build

== Usage

=== General

The configuration controlled in the docker-compose configuration file.
The default file is dc.yaml.default.
The key elements for the behavior of pyff and pyffd are:

* Environment variables
* Configuration in /etc/pki/sign, /etc/pyff
* Input data n /var/md_source

For initial testing copy sample data from /opt/testdata:

    cp -p /opt/testdata/etc/pyff/* /etc/pyff/
    cp -pr /opt/testdata/etc/pki/sign/* /etc/pki/sign/
    cp -pr /opt/testdata/md_source/* /var/md_source/

Other elements in the docker-compose configuration to be adpapted are:

* service and volume names if running mor than one instance on a node
* image (control deployed version with the tag value)
* networks

=== pyff (Aggregator))

Functional enhancements to pyFF:
- Commit generated aggregate to git repo
- Generate HTML pages for IDPs and SPs.
- Generate one signed file per entity 

=== Configuration

. Environment variables (independend of signing mechanism)
[cols="2,4"]
|===
| MDSIGN_CERT, MDSIGN_KEY | Key pair for metadata signing, must match pipeline definition (see md/mdx_swcert.fd)
| MD_AGGREGATE | Output file defined in pipeline definition to be use as input for split operation (options -s
| MDFEED_HOST MDFEED_REPO MDFEED_SSHUSER | Access to output Repo whan using pyff_aggregate.sh -g
| MDSPLIT_UNSIGNED | Directory where mdsplit will store unsigned EntityDescriptor files
| MDSPLIT_SIGNED | Directory where mdsplit will store signed EntityDescriptor files
| PIPELINEBATCH | Aggregator configuration (by default in /etc/pyff)
|===

. Environment variables (using PKCS11 device for signing)
[cols="2,4"]
|===
| PKCS11USBDEVICE | Name of device used as regex to match output from lsusb (replace blanks wih '.'). E.g. 'Aladdin.Knowledge.Systems.Token.JC'
| PKCS11LIBDEVICE | Name of device slot in Cryptoki Library, with blanks replaced by '.' (e.g.'eToken.5110')
| P11KIT_DESC | Name of Device in p11.kit (rquired for test script)
| PYKCS11LIB | Driver for HSM token
| PKCS11_CARD_DRIVER | same as PYKCS11LIB
| PYKCS11PIN | HSM user PIN
| SOFTHSM | Set to True to use SoftHSM; otherwise an error is raised if the HSM is not found
| SOPIN | HSM Security Officer PIN
|===

.Aggregator configuration
The aggregator configuration (/etc/pyff/*.fd) controls the selection of the input, processing, signing and output location.
The "finalize" key needs to be adapted accoring to the federation policy.
There might be multiple files, e.g. to separate files for IDPs, SPs and a combined aggregate.

=== Git Authentication
If the git pull/push operations require authentication your need to provide a default ssh keypair
and register it with Github (Gitlab, ..) in the home directory of the container user, such as:

    docker-compose -f dc.yaml exec pyff bash
    ssh-keygen -t ed25519
    # add ~/.ssh/id_ed25519.pub as a deploy key with write access to the remote repo
    ssh -T git@github.com  # validate that the github key fingerprint is valid
    git config --global push.default simple

=== Run aggregator

Start pyff:

    # see exec_pyff_batch.sh -h for options with per-entity-descriptor outpout and git integration
    ./exec_pyff_batch.sh

Sample entry for /etc/crontab to run pyff every hour:

    29 *  *  *  *  root /docker_images/pyff/exec_pyff_batch.sh 2>&1 > /var/log/exec_pyff_batch.log


== HSM/pyFF config

Config the key name in md_aggregate_sign.fd to match the key name on the HSM.
(See the line with 'sign -> key')

Provide the PYKCS11PIN env variable if using the HSM.


=== pyffd (IDP discovery service)

pyffd needs a pipeline definition (e.g. /opt/testdata/etc/pyff/mdx_softhsm.fd) and
key material either as sw-certificate or PKCS11 device.
The file with the pipeline definition must match PIPELINEDAEMON in dc.yaml.
Modify the configuration to reflect your metadata policy.


Configure environment variables in dc.yaml and start the daemon:


. Environment variables
|===
| MDSIGN_CERT, MDSIGN_KEY | Key pair for metadata signing, must match pipeline definition (see md/mdx_swcert.fd)
| FREQUENCY | refresh metadata interval
| PIDFILE | pid of pyffd
| PIPELINEDAEMON | pyffd configuration file
|===


    docker-compose -f dc.yaml up -d
    curl http://localhost:8080

Take care of appropriate port mapping and/or proxying.

Documentation: See https://github.com/IdentityPython/pyFF



== CI, Staging and Versioning

There is a Jenkinsfile for CI. To use it the jenkins user:

 * Must be able to run docker and docker-compose;
 * Must have python3 in the path;
 * Must have pytest and pyYaml installed in python3

== checking for errors

By default, pyff is rather silent and does not output error conditions (to be fixed).
For tracking problems:

    export LOGLEVEL=DEBUG
